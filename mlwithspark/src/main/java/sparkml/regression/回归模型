分类模型处理表示类别的离散变量，而回归模型则处理可以取任意实数的目标变量。
但是二者基本的原则类似，都是通过确定一个模型，将输
入特征映射到预测的输出。回归模型和分类模型都是监督学习的一种形式

回归模型可以用来预测任何目标，下面是几个例子。
 预测股票收益和其他经济相关的因素；
 预测贷款违约造成的损失（可以和分类模型相结合，分类模型预测违约概率，回归模型预测违约损失）；
 推荐系统（第4章中的交替最小二乘分解模型在每次迭代时都使用了线性回归）；
 基于用户的行为和消费模式，预测顾客对于零售、移动或者其他商业形态的存在价值。

Spark的MLlib库提供了两大回归模型：线性模型和决策树模型。
线性回归模型
    本质上和对应的线性分类模型一样，唯一的区别是线性回归使用的损失函数、相关连接函数和决策函数不同
    <最小二乘回归>

决策树回归
    同样可以通过改变不纯度的度量方法用于回归分析
    决策树在用于回归时也要使用对应的不纯度度量
    方法。这里的不纯度度量方法是方差，和最小二乘回归模型定义方差损失的方式一样


从数据中抽取合适的特征


评论回归模型的性能
    1.均方误差和均方根误差
    2.平均绝对误差
    3.均方根对数误差
    4.R-平方系统

改进模型性能与参数调优
    变换目标变量
        对数变换

    参数调优
        线性模型
            迭代
            步长
            正则化
            截距

        决策树
            树深度
            最大划分数








